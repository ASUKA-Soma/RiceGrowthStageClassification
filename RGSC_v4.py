import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import tempfile
import pandas as pd
import torch
import os
import plotly.express as px
import io
import matplotlib.pyplot as plt

# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
def load_model():
    use_model = st.sidebar.selectbox("ãƒ¢ãƒ‡ãƒ«", ['YOLO11m', 'YOLO11n'])
    if use_model == 'YOLO11m':
        model = YOLO('yolo11m.pt')
        conf = 0.568
    else:
        model = YOLO('yolo11n.pt')
        conf = 0.664
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    return model, conf, use_model, device

# UIã‚’åˆæœŸåŒ–
def initialize_ui(device):
    st.title('ç¨²æˆé•·æ®µéšåˆ†é¡AI')
    st.text("ver.4")
    st.text(f"{device}ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’è¡Œã„ã¾ã™ï¼")

# å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
def upload_video():
    return st.file_uploader("å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type='mp4')

# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
def upload_csv():
    return st.file_uploader("CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type='csv')

# å‹•ç”»ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°ï¼ˆæ¨è«–ï¼‹ä¿å­˜ï¼‰
def process_video(upload_file, model, conf, use_model, batch_size=8, input_size=640):
    if upload_file is not None:
        if st.button(f'{use_model}ã§æ¨è«–ã‚’é–‹å§‹ã™ã‚‹'):
            status_text = st.empty()
            progress_bar = st.progress(0)

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_file:
                temp_file.write(upload_file.read())
                temp_file_path = temp_file.name

            cap = cv2.VideoCapture(temp_file_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)

            filename = f"{os.path.splitext(upload_file.name)[0]}_{use_model}_result.mp4"
            writer = cv2.VideoWriter(filename,
                                    cv2.VideoWriter_fourcc(*'MP4V'),
                                    fps,
                                    (width, height))

            num = 0
            nums, leafs, leaf3, leaf4, leaf5, leaf6 = [], [], [], [], [], []
            batch_imgs = []  # ãƒãƒƒãƒç”¨ã®ç”»åƒãƒªã‚¹ãƒˆ
            batch_originals = []  # å…ƒã®ã‚µã‚¤ã‚ºã®ç”»åƒãƒªã‚¹ãƒˆ

            with torch.no_grad():  # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚
                while cap.isOpened():
                    ret, img = cap.read()
                    if not ret:
                        break

                    # **ğŸ“Œ â‘  YOLO ã®è¦æ±‚ã™ã‚‹ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º**
                    img_resized = cv2.resize(img, (input_size, input_size))  # 640x640ã«ãƒªã‚µã‚¤ã‚º
                    batch_imgs.append(img_resized)
                    batch_originals.append(img)  # å…ƒã®ã‚µã‚¤ã‚ºã®ç”»åƒã‚‚ä¿æŒ
                    num += 1

                    # ãƒãƒƒãƒãŒæº€ãŸã•ã‚ŒãŸã‚‰æ¨è«–
                    if len(batch_imgs) == batch_size or num == count:
                        batch_tensor = [torch.from_numpy(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)).permute(2, 0, 1).float() / 255.0 for im in batch_imgs]
                        batch_tensor = torch.stack(batch_tensor).to(model.device)

                        # **ğŸš€ â‘¡ ãƒãƒƒãƒæ¨è«–**
                        batch_results = model(batch_tensor, conf=conf)

                        # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®çµæœã‚’å‡¦ç†
                        for i, img_result in enumerate(batch_results):
                            img_original = batch_originals[i]  # **å…ƒã®ã‚µã‚¤ã‚ºã®ç”»åƒ**
                            img_annotated = img_result.plot(labels=True, conf=True)

                            # **ğŸ“Œ â‘¢ äºˆæ¸¬çµæœã‚’å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºã—ã¦ä¿å­˜**
                            img_annotated = cv2.resize(img_annotated, (width, height))
                            writer.write(img_annotated)

                            categories = img_result.boxes.cls
                            leaf_num = len(categories)
                            leaf3_num = torch.sum(torch.eq(img_result.boxes.cls, 0)).item()
                            leaf4_num = torch.sum(torch.eq(img_result.boxes.cls, 1)).item()
                            leaf5_num = torch.sum(torch.eq(img_result.boxes.cls, 2)).item()
                            leaf6_num = torch.sum(torch.eq(img_result.boxes.cls, 3)).item()

                            nums.append(num - len(batch_imgs) + i + 1)
                            leafs.append(leaf_num)
                            leaf3.append(leaf3_num)
                            leaf4.append(leaf4_num)
                            leaf5.append(leaf5_num)
                            leaf6.append(leaf6_num)

                        batch_imgs = []  # ãƒãƒƒãƒã‚¯ãƒªã‚¢
                        batch_originals = []

                    # é€²æ—è¡¨ç¤º
                    if num % 30 == 0:
                        progress = int(100 * num / count)
                        progress_bar.progress(min(progress, 100))
                        status_text.text(f"å‡¦ç†ä¸­... {progress}% ({num}/{count})")

            cap.release()
            writer.release()
            os.remove(temp_file_path)  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤

            progress_bar.progress(100)
            status_text.text("å‡¦ç†å®Œäº†ï¼")

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            leaf_data = pd.DataFrame({'frame': nums, 'leafs': leafs, 'leaf3': leaf3, 'leaf4': leaf4, 'leaf5': leaf5, 'leaf6': leaf6})
            leaf_data['sec'] = leaf_data['frame'] / fps
            leaf_data = leaf_data[['sec', 'leafs', 'leaf3', 'leaf4', 'leaf5', 'leaf6']]

            return leaf_data, leaf3, leaf4, leaf5, leaf6

    return None, None, None, None, None

# CSVè¡¨ç¤º
def generate_csv(upload_file):
    if upload_file is not None:
        data = pd.read_csv(upload_file)
        data = data.dropna()
        #st.dataframe(data)
        return data


def generate_map_timeline(df):
    if df is not None:
        # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        fig, ax = plt.subplots(figsize=(8, 6))  # fig, ax ã‚’æ˜ç¤ºçš„ã«å–å¾—
        scatter = ax.scatter(df["longitude"], df["latitude"], c=range(len(df)), cmap='viridis', marker='o', edgecolor='k')
    
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã‚’è¿½åŠ 
        cbar = plt.colorbar(scatter, ax=ax, label="Time Step")

        ax.set_xlabel("Longitude")
        ax.set_ylabel("Latitude")
        ax.set_title("Position Over Time")

        # Streamlit ã§è¡¨ç¤º
        st.pyplot(fig)


def aggregate_variable_blocks(df, target_rows):
    """
    æŒ‡å®šã—ãŸ target_rows è¡Œã«åœ§ç¸®ã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰å‰‡çš„ãªãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã§é›†ç´„ã™ã‚‹ã€‚
    """
    df = df.copy()  # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ã‚³ãƒ”ãƒ¼
    total_rows = len(df)
    
    step = total_rows / target_rows  # 1ãƒ–ãƒ­ãƒƒã‚¯ã‚ãŸã‚Šã®ç›®æ¨™è¡Œæ•°ï¼ˆå°æ•°å€¤ï¼‰
    
    # å„ãƒ–ãƒ­ãƒƒã‚¯ã®ç¯„å›²ã‚’æ±ºå®š
    block_ranges = [int(step * (i + 1)) for i in range(target_rows)]
    block_sizes = np.diff([0] + block_ranges)  # å„ãƒ–ãƒ­ãƒƒã‚¯ã®è¡Œæ•°
    
    # å„ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
    grouped_data = []
    start = 0
    for block_size in block_sizes:
        if block_size <= 0:  # å¿µã®ãŸã‚ç•°å¸¸ãªå€¤ã‚’å›é¿
            continue
        
        block_df = df.iloc[start:start + block_size]
        start += block_size
        
        aggregated = {
            'sec': block_df['sec'].mean(),  # sec ã¯å¹³å‡
            'leafs': block_df['leafs'].sum(),  # è‘‰ã®ç·æ•°
            'leaf3': block_df['leaf3'].sum(),
            'leaf4': block_df['leaf4'].sum(),
            'leaf5': block_df['leaf5'].sum(),
            'leaf6': block_df['leaf6'].sum()
        }

        # leaf_ave ã®å†è¨ˆç®—
        if aggregated['leafs'] == 0:
            aggregated['leaf_ave'] = 0  # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
        else:
            aggregated['leaf_ave'] = (
                aggregated['leaf3'] * 3 +
                aggregated['leaf4'] * 4 +
                aggregated['leaf5'] * 5 +
                aggregated['leaf6'] * 6
            ) / aggregated['leafs']
        
        grouped_data.append(aggregated)

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    grouped_df = pd.DataFrame(grouped_data)
    
    return grouped_df


# çµæœã‚’å¯è¦–åŒ–
def generate_charts(leaf_data, leaf3, leaf4, leaf5, leaf6):
    if leaf_data is not None:
        data = pd.DataFrame({
            "è‘‰é½¢": ['3è‘‰æœŸ', '4è‘‰æœŸ', '5è‘‰æœŸ', '6è‘‰æœŸ'],
            "å€¤": [sum(leaf3), sum(leaf4), sum(leaf5), sum(leaf6)]
        })

        # å††ã‚°ãƒ©ãƒ•ã‚’æç”»
        fig = px.pie(data, values='å€¤', names='è‘‰é½¢', title="å„è‘‰é½¢ã®å‰²åˆ", color_discrete_sequence=px.colors.qualitative.Set3)
        st.plotly_chart(fig)

        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        st.markdown("### ğŸŒŸ æ™‚åˆ»ã”ã¨ã®è‘‰é½¢ã®æ¨ç§»")
        st.line_chart(leaf_data, x="sec")

        # å‰²åˆã‚’è¡¨ç¤º
        total_leafs = sum(leaf3) + sum(leaf4) + sum(leaf5) + sum(leaf6)
        if total_leafs > 0:
            st.text(f'3è‘‰ç‡ï¼š{sum(leaf3) / total_leafs * 100:.2f}%ï¼Œ'
                    f'4è‘‰ç‡ï¼š{sum(leaf4) / total_leafs * 100:.2f}%ï¼Œ'
                    f'5è‘‰ç‡ï¼š{sum(leaf5) / total_leafs * 100:.2f}%ï¼Œ'
                    f'6è‘‰ç‡ï¼š{sum(leaf6) / total_leafs * 100:.2f}%')

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        #st.dataframe(leaf_data)

def merge_dataframes(df1, df2, join_type="outer"):
    merged_df = pd.concat([df1, df2], axis=1, join=join_type)
    #st.dataframe(merged_df)
    
    # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    fig, ax = plt.subplots(figsize=(8, 6))  # fig, ax ã‚’æ˜ç¤ºçš„ã«å–å¾—
    ax.set_facecolor('lightblue')
    #scatter = ax.scatter(merged_df["longitude"], merged_df["latitude"], 
    # c=merged_df["leaf_ave"], cmap='viridis', marker='o', edgecolor='k')
    
    # 0 ã§ã¯ãªã„ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚«ãƒ¼ã¯ 'o'
    mask_3 = merged_df["leaf_ave"] > 2.5
    scatter = ax.scatter(merged_df["longitude"][mask_3], merged_df["latitude"][mask_3], 
               c='green', marker='o', edgecolor='k', vmin=3, vmax=6, label="leaf3")
    mask_4 = merged_df["leaf_ave"] > 3.5
    scatter = ax.scatter(merged_df["longitude"][mask_4], merged_df["latitude"][mask_4], 
               c='yellow', marker='o', edgecolor='k', vmin=3, vmax=6, label="leaf4")
    mask_5 = merged_df["leaf_ave"] > 4.5
    scatter = ax.scatter(merged_df["longitude"][mask_5], merged_df["latitude"][mask_5], 
               c='orange', marker='o', edgecolor='k', vmin=3, vmax=6, label="leaf5")
    mask_6 = merged_df["leaf_ave"] > 5.5
    scatter = ax.scatter(merged_df["longitude"][mask_6], merged_df["latitude"][mask_6], 
               c='red', marker='o', edgecolor='k', vmin=3, vmax=6, label="leaf6")
    
    # 0 ã®ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚«ãƒ¼ã¯ 'x'
    #mask_zero = merged_df["leaf_ave"] == 0
    #ax.scatter(merged_df["longitude"][mask_zero], merged_df["latitude"][mask_zero], 
    #           c='black', marker='x', edgecolor='k')

    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã‚’è¿½åŠ 
    #cbar = plt.colorbar(scatter, ax=ax, label="Leaf Stage")
    ax.legend(title="Leaf Stage")

    ax.set_xlabel("Longitude")
    ax.set_ylabel("Latitude")
    ax.set_title("Position Leaf Stage")

    # Streamlit ã§è¡¨ç¤º
    st.pyplot(fig)



# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    model, conf, use_model, device = load_model()
    initialize_ui(device)
    upload_file = upload_video()
    csv = upload_csv()
    
    df_gps = generate_csv(csv)
    leaf_data, leaf3, leaf4, leaf5, leaf6 = process_video(upload_file, model, conf, use_model)
    
    generate_charts(leaf_data, leaf3, leaf4, leaf5, leaf6)
    #generate_map_timeline(df_gps)

    if leaf_data is not None:
        df_leaf = aggregate_variable_blocks(leaf_data, len(df_gps))
        #st.dataframe(df_leaf)
        #st.dataframe(df_gps)
        merge_dataframes(df_leaf, df_gps)
    


    

if __name__ == "__main__":
    main()
